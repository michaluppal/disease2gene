{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Python Script for Full-Text Article Fetching: A Step-by-Step Explanation\n",
        "\n",
        "This script acts as a follow-up, designed to fetch the full text of scientific papers identified by their PubMed IDs (PMIDs), likely using the output from a script like the previous one you shared.\n",
        "\n",
        "**Overall Goal:**\n",
        "\n",
        "The primary purpose of this script is to:\n",
        "1.  Read a list of PMIDs from a CSV file (presumably generated by a prior literature search script).\n",
        "2.  For each PMID, visit its PubMed page to find links to the full-text article.\n",
        "3.  Prioritize links to PubMed Central (PMC) or other open access repositories if available.\n",
        "4.  Download the full-text content (HTML or XML) of the article from the publisher's website or repository.\n",
        "5.  Save this downloaded content efficiently, avoiding re-downloading if the content for a PMID has already been fetched.\n",
        "6.  Use parallel processing to speed up the fetching of multiple articles.\n",
        "\n",
        "---\n",
        "\n",
        "## The Pipeline: Step-by-Step Explanation\n",
        "\n",
        "### Phase 1: Setup and Configuration\n",
        "\n",
        "This section imports necessary Python libraries and defines global settings for the script's operation.\n",
        "\n",
        "* **Imports (Lines 2-9 in the script):**\n",
        "    * `requests`: For making HTTP requests to fetch web pages.\n",
        "    * `BeautifulSoup` (from `bs4`): For parsing HTML and XML content to extract information.\n",
        "    * `pandas`: For reading and handling data from CSV files.\n",
        "    * `time`: For adding delays (important for politeness when scraping).\n",
        "    * `pickle`: For serializing and de-serializing Python objects (saving and loading data like dictionaries).\n",
        "    * `gzip`: For compressing and decompressing files (to save disk space).\n",
        "    * `glob`: For finding files matching a pattern (e.g., finding all CSV files).\n",
        "    * `os`: For interacting with the operating system (e.g., checking file existence, getting file modification times).\n",
        "    * `logging`: For recording script activity and errors to a file.\n",
        "    * `urljoin` (from `urllib.parse`): For constructing absolute URLs from relative ones.\n",
        "    * `concurrent.futures`: For running tasks in parallel, making the script faster.\n",
        "\n",
        "* **Configuration (Lines 11-18):**\n",
        "    * `logging.basicConfig(...)`: Configures how logs are recorded. Errors and informational messages will be saved to `fetch_papers_errors.log`.\n",
        "    * `REQUEST_HEADERS`: A dictionary defining HTTP headers to be sent with each request. The `User-Agent` mimics a web browser, which can sometimes be necessary to access websites that might block basic script requests.\n",
        "    * `FETCH_DELAY_SECONDS`: A crucial delay (in seconds) applied *before* fetching the actual full-text from a publisher or PMC site. This is to be polite and avoid overwhelming servers.\n",
        "    * `MAX_WORKERS`: The number of parallel threads the script will use to fetch papers simultaneously.\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 2: Helper Functions\n",
        "\n",
        "These are reusable blocks of code that perform specific tasks.\n",
        "\n",
        "1.  **`fetch_url_content(url, retries=1, base_retry_delay=1, timeout=1)` function:**\n",
        "    * **Purpose:** A robust function to download the content of a given URL.\n",
        "    * **How it works:**\n",
        "        * It attempts to get the URL using `requests.get()`, including the `REQUEST_HEADERS`.\n",
        "        * It has a `timeout` to prevent hanging indefinitely on a slow response.\n",
        "        * `response.raise_for_status()`: Checks if the request was successful (e.g., status code 200 OK). If not (e.g., 404 Not Found, 500 Server Error), it raises an error.\n",
        "        * **Retries:** If a request fails (due to timeout, HTTP error other than 404, or general request error), it waits for an increasing `base_retry_delay` and tries again, up to the specified number of `retries`.\n",
        "        * Logs success, warnings, and errors.\n",
        "    * **Output:** Returns the `response` object if successful, otherwise `None`.\n",
        "\n",
        "2.  **`get_full_text_data(pmid: str)` function:**\n",
        "    * **Purpose:** This is the core function that takes a single PMID, finds its full-text link on PubMed, and then attempts to download the content.\n",
        "    * **How it works (step-by-step for one PMID):**\n",
        "        1.  **Construct PubMed URL:** Creates the URL for the PMID's page on PubMed (e.g., `https://pubmed.ncbi.nlm.nih.gov/YOUR_PMID/`).\n",
        "        2.  **Fetch PubMed Page:** Uses `fetch_url_content` to download the HTML of this PubMed page. If this fails, it logs an error and returns an error dictionary.\n",
        "        3.  **Parse PubMed Page for Links:**\n",
        "            * Uses `BeautifulSoup` to parse the HTML.\n",
        "            * It looks for a `div` with class `full-text-links-list` which usually contains links to the full article.\n",
        "            * If that `div` isn't found, it looks for a single prominent link (class `link-item dialog-focus`).\n",
        "            * If no links are found, it logs a warning and returns an error dictionary.\n",
        "        4.  **Prioritize Full-Text Links:**\n",
        "            * It iterates through the found links.\n",
        "            * It gives priority to links that point to **PubMed Central (PMC)** or **Europe PMC** (e.g., containing \"ncbi.nlm.nih.gov/pmc\" or \"europepmc.org\" in the URL, or \"pmc\" in the link text or attributes). These sites often provide open access or more structured XML versions of articles.\n",
        "            * If a PMC link is found, it's chosen, and the script moves on.\n",
        "            * If no PMC link is found after checking all links, it defaults to using the first link found on the PubMed page.\n",
        "            * If no valid URL can be resolved, it returns an error.\n",
        "        5.  **Fetch Full-Text Content:**\n",
        "            * **Crucial Delay:** `time.sleep(FETCH_DELAY_SECONDS)` is called *before* accessing the chosen `full_text_target_url` (the publisher's site or PMC). This helps prevent being blocked or seen as aggressive.\n",
        "            * Uses `fetch_url_content` again to download the actual article content from the target URL.\n",
        "        6.  **Determine Content Type and Return:**\n",
        "            * If the article content is successfully fetched:\n",
        "                * It checks the `Content-Type` header of the response. If it indicates XML, the `determined_type` is set to 'xml'.\n",
        "                * It also has a special check for PMC links: if the text looks like XML (starts with `<` and contains tags like `<article>` or `<front>`), it's marked as 'xml'. Otherwise, it's assumed to be 'html'.\n",
        "                * It returns a dictionary containing the `pmid`, the `determined_type` ('html', 'xml', or 'error'), the downloaded `content` (text), and the `final_url` from which the content was fetched.\n",
        "            * If fetching the full content fails, it returns an error dictionary.\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 3: Main Script Logic (`main()` function)\n",
        "\n",
        "This function orchestrates the overall process.\n",
        "\n",
        "1.  **Find Input CSV:**\n",
        "    * `glob.glob('pubmed_genetic_results_*.csv')`: Searches the current directory for CSV files starting with \"pubmed\\_genetic\\_results\\_\".\n",
        "    * `latest_csv_file = max(csv_files, key=os.path.getctime)`: Selects the most recently modified CSV file from the found list. This is assumed to be the input file containing PMIDs.\n",
        "    * Logs which CSV file is being used.\n",
        "\n",
        "2.  **Load PMIDs from CSV:**\n",
        "    * `df = pd.read_csv(latest_csv_file)`: Reads the selected CSV file into a pandas DataFrame.\n",
        "    * Error handling is in place for `FileNotFoundError` or other issues during CSV reading.\n",
        "    * Checks if a 'PMID' column exists in the DataFrame.\n",
        "    * `all_pmids_from_csv = df['PMID'].astype(str).unique().tolist()`: Extracts all unique PMIDs from the 'PMID' column and converts them to a list of strings.\n",
        "\n",
        "3.  **Load Existing Content (if any):**\n",
        "    * `output_filename = \"content_dict.pkl.gz\"`: Defines the name of the file where downloaded content will be stored (a compressed pickle file).\n",
        "    * `content_dict = {}`: Initializes an empty dictionary to store results.\n",
        "    * **Resuming Progress:** If `output_filename` already exists, the script tries to load its content using `gzip.open` and `pickle.load`. This allows the script to resume from where it left off, avoiding re-downloading already fetched PMIDs.\n",
        "    * If loading fails, it starts with an empty `content_dict`.\n",
        "\n",
        "4.  **Determine PMIDs to Fetch:**\n",
        "    * `pmids_to_fetch = [pmid for pmid in all_pmids_from_csv if pmid not in content_dict]`: Creates a list of PMIDs that are in the CSV but not yet in the `content_dict` (i.e., new PMIDs that need to be fetched).\n",
        "    * If `pmids_to_fetch` is empty, it means all PMIDs from the CSV have already been processed, so the script prints a message and exits.\n",
        "\n",
        "5.  **Parallel Fetching of New Content:**\n",
        "    * If there are `pmids_to_fetch`:\n",
        "        * It uses `concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS)`. This creates a pool of worker threads that can execute tasks in parallel.\n",
        "        * `future_to_pmid = {executor.submit(get_full_text_data, pmid): pmid for pmid in pmids_to_fetch}`: For each `pmid` in `pmids_to_fetch`, it submits the `get_full_text_data` function (with that `pmid` as an argument) to the executor. `executor.submit` immediately returns a `Future` object, which represents the pending result of the task. This dictionary maps `Future` objects back to their corresponding PMIDs.\n",
        "        * `tqdm(...)`: A library that provides a progress bar for loops. `concurrent.futures.as_completed(future_to_pmid)` yields `Future` objects as they complete (not necessarily in the order they were submitted).\n",
        "        * As each `future` completes:\n",
        "            * `data = future.result()`: Retrieves the result from the completed task (the dictionary returned by `get_full_text_data`).\n",
        "            * If an exception occurred within the task, it's logged, and an error dictionary is appended to `results_from_fetch`.\n",
        "            * Otherwise, the successful `data` is appended.\n",
        "\n",
        "6.  **Update `content_dict` and Save Results:**\n",
        "    * It iterates through the `results_from_fetch`.\n",
        "    * For each `result_item`:\n",
        "        * The `pmid` is extracted.\n",
        "        * The `content_dict` is updated with the new data for that `pmid`. It's careful not to overwrite potentially valid older data with a new error if a PMID was somehow re-queued (though the main logic should prevent this).\n",
        "        * A counter `newly_processed_count` tracks how many PMIDs were successfully processed in *this run*.\n",
        "    * **Saving Data:** If any new processing was attempted (`results_from_fetch` is not empty):\n",
        "        * The entire (updated) `content_dict` is saved to `output_filename` using `pickle.dump` and `gzip.open` for compression.\n",
        "        * Logs and prints information about the number of newly processed PMIDs and the total entries in the saved file.\n",
        "    * If no new PMIDs were processed, it prints a message indicating that.\n",
        "\n",
        "7.  **Final Report:**\n",
        "    * Logs and prints the total number of new PMIDs successfully processed in the current run and the total number of entries now in the `content_dict.pkl.gz` file.\n",
        "\n",
        "8.  **Script Execution Trigger (`if __name__ == \"__main__\":`)**\n",
        "    * This standard Python construct ensures that the `main()` function is called only when the script is executed directly (not when it's imported as a module into another script).\n",
        "\n",
        "---\n",
        "\n",
        "This script is a practical tool for researchers needing to gather full-text data for large sets of articles, with considerations for efficiency (parallelism, resuming progress) and politeness to web servers (delays)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho5RPh6wOTFg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import pickle\n",
        "import gzip\n",
        "import glob\n",
        "import os\n",
        "import logging\n",
        "from urllib.parse import urljoin\n",
        "import concurrent.futures # For parallelization\n",
        "\n",
        "# --- Configuration ---\n",
        "logging.basicConfig(filename='fetch_papers_errors.log', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "REQUEST_HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "# This delay is applied *before* fetching the final full-text URL from a publisher/PMC site by each worker.\n",
        "FETCH_DELAY_SECONDS = 2 # Slightly reduced, but still important for politeness.\n",
        "MAX_WORKERS = 5 # Number of parallel threads. Adjust based on your network and CPU. Too many can still cause issues.\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def fetch_url_content(url, retries=1, base_retry_delay=1, timeout=1):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url, headers=REQUEST_HEADERS, timeout=timeout, allow_redirects=True)\n",
        "            response.raise_for_status()\n",
        "            logging.info(f\"Successfully fetched {url} with status {response.status_code}\")\n",
        "            return response\n",
        "        except requests.exceptions.Timeout:\n",
        "            logging.warning(f\"Timeout on attempt {attempt + 1}/{retries} for {url}\")\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            logging.warning(f\"HTTP error {e.response.status_code} on attempt {attempt + 1}/{retries} for {url}\")\n",
        "            if e.response.status_code == 404: # Don't retry if not found\n",
        "                break\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logging.warning(f\"Request error on attempt {attempt + 1}/{retries} for {url}: {e}\")\n",
        "\n",
        "        if attempt < retries - 1:\n",
        "            # Simple incremental backoff for retries\n",
        "            current_delay = base_retry_delay * (attempt + 1)\n",
        "            logging.info(f\"Waiting {current_delay} seconds before retry for {url}...\")\n",
        "            time.sleep(current_delay)\n",
        "    logging.error(f\"Failed to fetch {url} after {retries} retries.\")\n",
        "    return None\n",
        "\n",
        "def get_full_text_data(pmid: str):\n",
        "    pubmed_base_url = 'https://pubmed.ncbi.nlm.nih.gov/'\n",
        "    pmid_url = f'{pubmed_base_url}{pmid}/'\n",
        "    # Logging the start of processing for a PMID is now better done before submitting to the pool\n",
        "    # logging.info(f\"Processing PMID: {pmid} - URL: {pmid_url}\")\n",
        "\n",
        "    pubmed_response = fetch_url_content(pmid_url)\n",
        "    if not pubmed_response or not pubmed_response.text:\n",
        "        logging.error(f\"Failed to fetch PubMed page for PMID {pmid}\")\n",
        "        return {\"pmid\": pmid, \"type\": \"error\", \"content\": \"Failed to fetch PubMed page\", \"final_url\": pmid_url}\n",
        "\n",
        "    soup = BeautifulSoup(pubmed_response.text, 'html.parser')\n",
        "    full_text_div = soup.find('div', class_='full-text-links-list')\n",
        "    links_found = []\n",
        "\n",
        "    if not full_text_div:\n",
        "        logging.debug(f\"No 'full-text-links-list' div found for PMID {pmid}. Checking for single prominent link.\")\n",
        "        single_link = soup.find('a', class_='link-item dialog-focus')\n",
        "        if single_link and single_link.get('href'):\n",
        "             links_found = [single_link]\n",
        "             logging.debug(f\"Found single prominent full text link for PMID {pmid}\")\n",
        "        else:\n",
        "            logging.warning(f\"No full text links (list or single) found for PMID {pmid}\")\n",
        "            return {\"pmid\": pmid, \"type\": \"error\", \"content\": \"No full-text links found on PubMed page\", \"final_url\": pmid_url}\n",
        "    else:\n",
        "        links_found = full_text_div.find_all('a', class_='link-item')\n",
        "\n",
        "    if not links_found: # Should be caught above, but as a safeguard\n",
        "        logging.warning(f\"No links extracted from full_text_div or single link for PMID {pmid}\")\n",
        "        return {\"pmid\": pmid, \"type\": \"error\", \"content\": \"No links extracted from full_text_div\", \"final_url\": pmid_url}\n",
        "\n",
        "    full_text_target_url = None\n",
        "    is_pmc_link = False\n",
        "\n",
        "    for link in links_found:\n",
        "        href = link.get('href')\n",
        "        if not href:\n",
        "            continue\n",
        "\n",
        "        current_link_url = urljoin(pmid_url, href)\n",
        "        link_text_lower = link.get_text(strip=True).lower()\n",
        "        href_lower = href.lower()\n",
        "\n",
        "        if \"ncbi.nlm.nih.gov/pmc\" in current_link_url or \"europepmc.org\" in current_link_url or \\\n",
        "           \"pmc\" in link.get('data-ga-action', '').lower() or \"pmc\" in link_text_lower or \"pmc\" in href_lower:\n",
        "            full_text_target_url = current_link_url\n",
        "            is_pmc_link = True\n",
        "            logging.info(f\"Prioritized PMC link for PMID {pmid}: {full_text_target_url}\")\n",
        "            break\n",
        "\n",
        "    if not full_text_target_url and links_found:\n",
        "        first_link_href = links_found[0].get('href')\n",
        "        if first_link_href:\n",
        "            full_text_target_url = urljoin(pmid_url, first_link_href)\n",
        "            logging.info(f\"Using first available link (non-PMC priority) for PMID {pmid}: {full_text_target_url}\")\n",
        "\n",
        "    if not full_text_target_url:\n",
        "        logging.error(f\"No valid full text URL could be resolved for PMID {pmid}\")\n",
        "        return {\"pmid\": pmid, \"type\": \"error\", \"content\": \"No valid full-text URL resolved\", \"final_url\": pmid_url}\n",
        "\n",
        "    logging.info(f\"PMID {pmid}: Attempting to fetch full content from: {full_text_target_url}\")\n",
        "    time.sleep(FETCH_DELAY_SECONDS) # Crucial delay before hitting external sites\n",
        "\n",
        "    article_response = fetch_url_content(full_text_target_url)\n",
        "    if article_response and article_response.text:\n",
        "        content_type_header = article_response.headers.get('Content-Type', '').lower()\n",
        "        determined_type = 'html'\n",
        "\n",
        "        if 'xml' in content_type_header:\n",
        "            determined_type = 'xml'\n",
        "        elif is_pmc_link and \"PMC\" in full_text_target_url and not full_text_target_url.endswith(('.pdf', '.epub')):\n",
        "            if article_response.text.strip().startswith('<') and \\\n",
        "               (\"<article\" in article_response.text[:1000] or \"<front>\" in article_response.text[:1000]):\n",
        "                determined_type = 'xml'\n",
        "                logging.info(f\"Detected XML-like content from PMC for PMID {pmid} by inspection.\")\n",
        "\n",
        "        logging.info(f\"Successfully retrieved content for PMID {pmid} from {full_text_target_url}. Type: {determined_type}, Length: {len(article_response.text)}\")\n",
        "        return {\n",
        "            \"pmid\": pmid,\n",
        "            \"type\": determined_type,\n",
        "            \"content\": article_response.text,\n",
        "            \"final_url\": full_text_target_url\n",
        "        }\n",
        "    else:\n",
        "        logging.error(f\"Failed to fetch full content for PMID {pmid} from {full_text_target_url}\")\n",
        "        return {\"pmid\": pmid, \"type\": \"error\", \"content\": f\"Failed to fetch from {full_text_target_url}\", \"final_url\": full_text_target_url}\n",
        "\n",
        "# --- Main Script ---\n",
        "def main():\n",
        "    csv_files = glob.glob('pubmed_genetic_results_*.csv')\n",
        "    if not csv_files:\n",
        "        logging.error(\"No pubmed_genetic_results_*.csv files found in the current directory.\")\n",
        "        print(\"Error: No pubmed_genetic_results_*.csv files found.\")\n",
        "        return\n",
        "    latest_csv_file = max(csv_files, key=os.path.getctime)\n",
        "    logging.info(f\"Using input CSV file: {latest_csv_file}\")\n",
        "    print(f\"Using input CSV file: {latest_csv_file}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(latest_csv_file)\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"CSV file {latest_csv_file} not found.\")\n",
        "        print(f\"Error: {latest_csv_file} not found.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error reading CSV {latest_csv_file}: {e}\")\n",
        "        print(f\"Error reading CSV {latest_csv_file}: {e}\")\n",
        "        return\n",
        "\n",
        "    if 'PMID' not in df.columns:\n",
        "        logging.error(\"CSV file must contain a 'PMID' column.\")\n",
        "        print(\"Error: CSV file must contain a 'PMID' column.\")\n",
        "        return\n",
        "\n",
        "    all_pmids_from_csv = df['PMID'].astype(str).unique().tolist()\n",
        "    logging.info(f\"Found {len(all_pmids_from_csv)} unique PMIDs to process from {latest_csv_file}.\")\n",
        "    print(f\"Found {len(all_pmids_from_csv)} unique PMIDs to process.\")\n",
        "\n",
        "    content_dict = {}\n",
        "    output_filename = \"content_dict.pkl.gz\"\n",
        "\n",
        "    if os.path.exists(output_filename):\n",
        "        try:\n",
        "            with gzip.open(output_filename, 'rb') as f_load:\n",
        "                content_dict = pickle.load(f_load)\n",
        "            logging.info(f\"Loaded {len(content_dict)} existing entries from {output_filename}\")\n",
        "            print(f\"Loaded {len(content_dict)} existing entries from {output_filename}\")\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Could not load existing {output_filename}: {e}. Starting fresh.\")\n",
        "            content_dict = {}\n",
        "\n",
        "    pmids_to_fetch = [pmid for pmid in all_pmids_from_csv if pmid not in content_dict]\n",
        "    if not pmids_to_fetch:\n",
        "        print(\"All PMIDs from the CSV have already been processed. Nothing new to fetch.\")\n",
        "        logging.info(\"All PMIDs from the CSV have already been processed.\")\n",
        "        return\n",
        "\n",
        "    logging.info(f\"Attempting to fetch content for {len(pmids_to_fetch)} new PMIDs.\")\n",
        "    print(f\"Attempting to fetch content for {len(pmids_to_fetch)} new PMIDs.\")\n",
        "\n",
        "    # Using ThreadPoolExecutor for parallel fetching\n",
        "    # The main rate limiting per external site is handled by FETCH_DELAY_SECONDS within get_full_text_data\n",
        "    # MAX_WORKERS limits simultaneous calls to PubMed for initial pages.\n",
        "    results_from_fetch = []\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        future_to_pmid = {executor.submit(get_full_text_data, pmid): pmid for pmid in pmids_to_fetch}\n",
        "\n",
        "        for future in tqdm(concurrent.futures.as_completed(future_to_pmid), total=len(pmids_to_fetch), desc=\"Fetching paper content\", unit=\"PMID\"):\n",
        "            pmid = future_to_pmid[future]\n",
        "            try:\n",
        "                data = future.result()\n",
        "                if data:\n",
        "                    results_from_fetch.append(data)\n",
        "            except Exception as exc:\n",
        "                logging.error(f\"PMID {pmid} generated an exception during parallel execution: {exc}\")\n",
        "                results_from_fetch.append({\"pmid\": pmid, \"type\": \"error\", \"content\": f\"Exception: {exc}\", \"final_url\": None})\n",
        "\n",
        "    newly_processed_count = 0\n",
        "    for result_item in results_from_fetch:\n",
        "        pmid = result_item[\"pmid\"]\n",
        "        # Ensure we don't overwrite potentially valid older data with a new error if it was somehow re-queued\n",
        "        if pmid not in content_dict or content_dict[pmid].get(\"type\") == \"error\":\n",
        "             content_dict[pmid] = {\n",
        "                \"type\": result_item[\"type\"],\n",
        "                \"content\": result_item[\"content\"],\n",
        "                \"final_url\": result_item[\"final_url\"]\n",
        "            }\n",
        "        if result_item[\"type\"] != \"error\":\n",
        "            newly_processed_count +=1\n",
        "\n",
        "\n",
        "    if results_from_fetch: # Save if any new processing was attempted\n",
        "        try:\n",
        "            with gzip.open(output_filename, 'wb') as f_save:\n",
        "                pickle.dump(content_dict, f_save)\n",
        "            logging.info(f\"Saved results: {newly_processed_count} new PMIDs successfully processed in this run.\")\n",
        "            logging.info(f\"Total entries in {output_filename}: {len(content_dict)}\")\n",
        "            print(f\"\\nSaved results. Total entries in {output_filename}: {len(content_dict)}\")\n",
        "        except Exception as e_save:\n",
        "            logging.error(f\"Error saving final results to {output_filename}: {e_save}\")\n",
        "            print(f\"\\nError saving final results: {e_save}\")\n",
        "    else:\n",
        "        print(\"No new PMIDs were processed in this run.\")\n",
        "\n",
        "\n",
        "    logging.info(f\"Finished processing. Total new PMIDs successfully processed in this run: {newly_processed_count}\")\n",
        "    print(f\"\\nFetching complete. Total successfully processed new PMIDs: {newly_processed_count}. Total entries in {output_filename}: {len(content_dict)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e04fef4f527440b9e4f8f8ef8472a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89e652cef1d6405eb18db1790c24740f",
              "IPY_MODEL_9bcf34386fba4516b29ebcd510c56941",
              "IPY_MODEL_5014d8026ef44509864609a729db1988"
            ],
            "layout": "IPY_MODEL_5615ee6256ab4b4ab1bf0e69563c3726"
          }
        },
        "5014d8026ef44509864609a729db1988": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fbbfdec53364ed9ae7aa646619ff189",
            "placeholder": "​",
            "style": "IPY_MODEL_ed274e91a248415a80e3c2ebe4cf5846",
            "value": " 923/923 [09:23&lt;00:00,  1.62PMID/s]"
          }
        },
        "545e0df3a7c3414ba634f2caec0982ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5615ee6256ab4b4ab1bf0e69563c3726": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4294487b444d9b91f45b2547885739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f66c8f3155c45c2ae4e84adb5257988": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89e652cef1d6405eb18db1790c24740f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f66c8f3155c45c2ae4e84adb5257988",
            "placeholder": "​",
            "style": "IPY_MODEL_545e0df3a7c3414ba634f2caec0982ec",
            "value": "Fetching paper content: 100%"
          }
        },
        "9bcf34386fba4516b29ebcd510c56941": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caaca468cbdc4106879535853750c4d2",
            "max": 923,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c4294487b444d9b91f45b2547885739",
            "value": 923
          }
        },
        "9fbbfdec53364ed9ae7aa646619ff189": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caaca468cbdc4106879535853750c4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed274e91a248415a80e3c2ebe4cf5846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
